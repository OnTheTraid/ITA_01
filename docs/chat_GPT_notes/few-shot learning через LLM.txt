Как РЕАЛЬНО работает обучение в твоём проекте:
1. Обучение LLM на конкретном сетапе:
Процесс:

Ты загружаешь 20-50 размеченных скринов (ground truth examples)
Добавляешь текстовое описание правил сетапа (например "Frank raid: пробой Frankfurt high, reverse, FVG M1 inversion")
Показываешь LLM: "Вот так выглядит этот сетап, вот что нужно искать"
LLM "запоминает" через векторные embeddings в ChromaDB

2. Бэктест как проверка обучения:
Итерация обучения:

Бэктест за неделю → ты проверяешь результаты (нашла ли LLM то что нужно?)
Корректировка (добавление примеров, уточнение правил)
Бэктест за год → финальная проверка что LLM стабильно распознаёт сетап
Бэктест за 5 лет → подтверждение что сетап работает исторически

3. Где хранится "обучение":
ChromaDB (модуль 2.9.2):
chroma/
  └── collections/
      ├── theory_docs/          # Твои описания правил (text embeddings)
      ├── trade_cases/          # Твои 20-50 скринов (image embeddings CLIP)
      └── setup_Frank_raid_v1/  # Специфичная коллекция для этого сетапа
```

**Что там лежит:**
- **Text embeddings** твоих правил ("пробой франкфурт хай, reverse...")
- **Image embeddings** твоих размеченных PNG (CLIP векторы 512-dim)
- **Metadata** с каждым embedding: "это пример правильного Frank raid", "confidence=1.0"

### 4. **Как LLM использует это при бэктесте:**
```
Новая свеча на графике (backtest)
    ↓
Dash создаёт PNG
    ↓
Vision Adapter отправляет в GPT-4V:
    - PNG графика
    - Retrieval из ChromaDB: "похожие примеры Frank raid" (top-5 по similarity)
    - Правила из theory_docs
    ↓
GPT-4V анализирует: "Да, это Frank raid" или "Нет, условия не выполнены"
```

---

## Что НЕ так в моём предыдущем описании:

❌ **Я написал:** "ML модель обучается на признаках (confidence FVG, OB...)"
- Это был бы **классический ML подход** (sklearn, LightGBM)
- Но у тебя **НЕ такой подход**

✅ **На самом деле:** 
- Ты используешь **few-shot learning** через LLM
- "Обучение" = загрузка примеров в ChromaDB
- "Модель" = GPT-4 Vision + RAG (Retrieval Augmented Generation)